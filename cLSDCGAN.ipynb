{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms \n",
    "import torch.utils.data as Data\n",
    "import torchvision.transforms as T\n",
    "from glob import glob\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from torchvision.utils import save_image\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "to_img= T.Compose([T.ToPILImage()])\n",
    "to_tensor = T.Compose([T.ToTensor()])\n",
    "load_norm = T.Compose([T.ToTensor(),T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Parser():\n",
    "    #hyperparameters\n",
    "    def __init__(self):\n",
    "        #image setting\n",
    "        self.n_epoch = 50\n",
    "        self.batch_size = 64\n",
    "        self.z_dim = 100\n",
    "        self.y_dim = 2\n",
    "        self.D_lr = 0.01\n",
    "        self.G_lr = 0.002 # 0.0002\n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.img_size = 64\n",
    "        self.lam1 = 10\n",
    "        self.lam2 = 5\n",
    "        self.model_save_freq = 1000\n",
    "        self.img_save_freq = 100\n",
    "        self.show_freq = 50\n",
    "        self.model_path = './cLSDCGAN5/Model/'\n",
    "        self.img_path = './cLSDCGAN5/Image/' \n",
    "        self.conv_dim = 64\n",
    "        self.d_dim = 64\n",
    "        self.D_out_dim = 16\n",
    "        self.train_img_path = \"./data/celeba/\"\n",
    "        self.num_res = 5\n",
    "        self.D_mode = ''\n",
    "        self.G_mode = ''\n",
    "        self.L_mode = ''\n",
    "        \n",
    "args = Parser()  \n",
    "\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "if not os.path.exists(args.img_path):\n",
    "    os.makedirs(args.img_path)\n",
    "\n",
    "# For creating the data\n",
    "#######\n",
    "# df = pd.read_csv('./data/celeba/Anno/list_attr_celeba.txt',delim_whitespace=True)\n",
    "# path = list(df['Path'])\n",
    "# is_male = list(df['Male'])\n",
    "# is_male = [1 if i == 1 else 0 for i in is_male]\n",
    "# with open(\"Path_Male.pickle\", \"wb\") as fp:   \n",
    "#     pickle.dump([path,is_male], fp) \n",
    "\n",
    "class CelebADataset(Data.Dataset):\n",
    "    def __init__(self, mode='train', args=None):\n",
    "        \n",
    "        self.image_transform = T.Compose([\n",
    "            T.Resize((args.img_size,args.img_size)),\n",
    "            #T.RandomResizedCrop(args.img_size, scale=(1.0,1.0)),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "        \n",
    "        with open(\"Path_Male.pickle\", 'rb') as f:\n",
    "            self.path ,self.male= pickle.load(f)\n",
    "            print('Loaded')\n",
    "        self.path = self.path[:-2000] if mode == 'train' else self.path[-2000:]\n",
    "        self.male = self.male[:-2000] if mode == 'train' else self.male[-2000:]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        idx = index % len(self.path)\n",
    "        img = self.image_transform(Image.open(os.path.join(args.train_img_path,\n",
    "                                                             self.path[idx])))\n",
    "        \n",
    "        is_male = self.male[idx]\n",
    "        return img, is_male\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path)\n",
    "\n",
    "\n",
    "# dataset = CelebADataset(mode='train',args= args)\n",
    "# dataloader = DataLoader(dataset,batch_size=args.batch_size,shuffle=True,drop_last=True,pin_memory=True)\n",
    "# data_t = iter(dataloader).next()\n",
    "# plt.imshow(to_img(data_t[0][0]*0.5+0.5))\n",
    "# print('Label: ',data_t[1][0].item())\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            #nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim,dim,3,1,1),\n",
    "            nn.BatchNorm2d(dim),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            #nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim,dim,3,1,1),\n",
    "            nn.BatchNorm2d(dim),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        #nn.LeakyReLU(0.2,inplace=True)\n",
    "        return nn.LeakyReLU(0.2,inplace=True)(self.model(x) + x)\n",
    "\n",
    "class ConcatBlock_G(nn.Module):\n",
    "    def __init__(self,dim = 64):\n",
    "        super(ConcatBlock_G, self).__init__()\n",
    "\n",
    "        if args.G_mode == \"Upsample\":\n",
    "            self.model_z = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                #nn.ReflectionPad2d(1),\n",
    "                nn.Conv2d(args.z_dim,dim*2,3,1,1),\n",
    "                nn.BatchNorm2d(dim*2),\n",
    "                nn.LeakyReLU(0.2,inplace=True),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                #nn.ReflectionPad2d(1),\n",
    "                nn.Conv2d(dim*2,dim*4,3,1,1),\n",
    "                nn.BatchNorm2d(dim*4),\n",
    "                nn.LeakyReLU(0.2,inplace=True),\n",
    "            )\n",
    "\n",
    "            self.model_y = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                #nn.ReflectionPad2d(1),\n",
    "                nn.Conv2d(args.y_dim,dim*2,3,1,1),\n",
    "                nn.BatchNorm2d(dim*2),\n",
    "                nn.LeakyReLU(0.2,inplace=True),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                #nn.ReflectionPad2d(1),\n",
    "                nn.Conv2d(dim*2,dim*4,3,1,1),\n",
    "                nn.BatchNorm2d(dim*4),\n",
    "                nn.LeakyReLU(0.2,inplace=True),\n",
    "            )\n",
    "        elif args.G_mode == \"Deconv\":\n",
    "            self.model_z = nn.Sequential(\n",
    "                nn.ConvTranspose2d(args.z_dim,dim*4,4,1,0),\n",
    "                nn.BatchNorm2d(dim*4),\n",
    "                nn.LeakyReLU(0.2,inplace=True),\n",
    "            )\n",
    "            self.model_y = nn.Sequential(\n",
    "                nn.ConvTranspose2d(args.y_dim,dim*4,4,1,0),\n",
    "                nn.BatchNorm2d(dim*4),\n",
    "                nn.LeakyReLU(0.2,inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    def forward(self, data):\n",
    "        return torch.cat([self.model_z(data[0]), self.model_y(data[1])],1)\n",
    "    \n",
    "\n",
    "class Generator(nn.Module):    \n",
    "    '''\n",
    "    Only need y, \n",
    "    '''\n",
    "    def __init__(self, dim = 64):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        \n",
    "        if args.G_mode == \"Upsample\":\n",
    "            print(\"Use Upsample in Generator\")\n",
    "            res_seq = nn.ModuleList()\n",
    "            res_seq.extend([ResBlock(dim*4) for i in range(args.num_res)])\n",
    "            self.model = nn.Sequential(\n",
    "                ConcatBlock_G(dim),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                #nn.ReflectionPad2d(1),\n",
    "                nn.Conv2d(dim*8,dim*4,3,1,1),\n",
    "                nn.BatchNorm2d(dim*4),\n",
    "                nn.LeakyReLU(0.2,inplace=True),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                ResBlock(dim*4),\n",
    "                #nn.ReflectionPad2d(1),\n",
    "#                 nn.Conv2d(dim*4,dim*4,3,1,1),\n",
    "#                 nn.BatchNorm2d(dim*4),\n",
    "#                 nn.LeakyReLU(0.2,inplace=True),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                #nn.ReflectionPad2d(1),\n",
    "                nn.Conv2d(dim*4,dim*2,3,1,1),\n",
    "                nn.BatchNorm2d(dim*2),\n",
    "                nn.LeakyReLU(0.2,inplace=True),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                #nn.ReflectionPad2d(1), # Can be deleted? \n",
    "                nn.Conv2d(dim*2,3,3,1,1),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        elif args.G_mode:\n",
    "            print(\"Use Deconv in Generator\")\n",
    "            self.model = nn.Sequential(\n",
    "                ConcatBlock_G(dim),\n",
    "                nn.ConvTranspose2d(dim*8,dim*4,4,2,1),\n",
    "                nn.BatchNorm2d(dim*4),\n",
    "                nn.LeakyReLU(0.2,inplace=True),\n",
    "                nn.ConvTranspose2d(dim*4,dim*4,4,2,1),\n",
    "                nn.BatchNorm2d(dim*4),\n",
    "                nn.LeakyReLU(0.2,inplace=True),\n",
    "                nn.ConvTranspose2d(dim*4,dim*2,4,2,1),\n",
    "                nn.BatchNorm2d(dim*2),\n",
    "                nn.LeakyReLU(0.2,inplace=True),\n",
    "                nn.ConvTranspose2d(dim*2,3,4,2,1),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "    def forward(self, y):  # Expect y as one hot code \n",
    "        self.z = torch.randn(args.batch_size, args.z_dim,1 ,1 ).to(device)\n",
    "        return self.model([self.z,y])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class ConcatBlock_D(nn.Module):\n",
    "    \n",
    "    def __init__(self,dim = 64):\n",
    "        super(ConcatBlock_D, self).__init__()\n",
    "        self.model_img = nn.Sequential(\n",
    "            nn.Conv2d(3,dim,4,2,1),\n",
    "            #nn.BatchNorm2d(dim),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.model_y = nn.Sequential(\n",
    "            nn.Conv2d(args.y_dim,dim,4,2,1),\n",
    "            #nn.BatchNorm2d(dim),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        ) \n",
    "        \n",
    "    def forward(self, data): # Expect repeatitive y 64x64\n",
    "        return torch.cat([self.model_img(data[0]),self.model_y(data[1])],1)\n",
    "        \n",
    "        \n",
    "\n",
    "class Discrimator(nn.Module):\n",
    "    def __init__(self, dim = 64):\n",
    "        super(Discrimator, self).__init__()\n",
    "        \n",
    "        #TODO : PatchGAN, Remove sigmoid function\n",
    "        if args.D_mode == \"Patch\":\n",
    "            print(\"Use PatchGAN Architecture in Discriminator\")\n",
    "            self.model = nn.Sequential(\n",
    "                ConcatBlock_D(dim),\n",
    "                nn.Conv2d(dim*2,dim*4,4,2,1),\n",
    "                nn.BatchNorm2d(dim*4),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv2d(dim*4,dim*8,4,2,1),\n",
    "                nn.BatchNorm2d(dim*8),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv2d(dim*8,dim*8,4,2,1),\n",
    "                nn.BatchNorm2d(dim*8),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv2d(dim*8,1,1,1,0),\n",
    "            )\n",
    "            \n",
    "        elif args.D_mode == \"Normal\":    \n",
    "            print(\"Use Normal Architecture in Discriminator\")\n",
    "            self.model = nn.Sequential(\n",
    "                ConcatBlock_D(dim),\n",
    "                nn.Conv2d(dim*2,dim*4,4,2,1),\n",
    "                nn.BatchNorm2d(dim*4),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv2d(dim*4,dim*8,4,2,1),\n",
    "                nn.BatchNorm2d(dim*8),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv2d(dim*8,dim*8,4,2,1),\n",
    "                nn.BatchNorm2d(dim*8),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv2d(dim*8,1,4,1,0),\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        if args.L_mode != \"LS\":\n",
    "            self.model.add_module('Sigmoid',nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, img, y): # Expect y as one hot code \n",
    "        y = y.repeat([1,1,args.img_size,args.img_size])\n",
    "        return self.model([img,y]) #Squeeze\n",
    "        \n",
    "\n",
    "\n",
    "class cLSDCGAN(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(cLSDCGAN, self).__init__()\n",
    "        \n",
    "        self.G = Generator(args.d_dim).to(device)\n",
    "        self.D = Discrimator(args.d_dim).to(device)\n",
    "        \n",
    "        if args.L_mode == 'LS':\n",
    "            print(\"Use LS Loss\")\n",
    "            self.Loss = nn.MSELoss().to(device)\n",
    "        elif args.L_mode == 'BCE':\n",
    "            print(\"Use BCE Loss\")\n",
    "            self.Loss = nn.BCELoss().to(device)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        self.G_loss_hist = []\n",
    "        self.D_loss_hist = []\n",
    "        \n",
    "        self.G_optim = optim.Adam(self.G.parameters(), lr = args.G_lr, betas=(args.b1, args.b2))\n",
    "        self.D_optim = optim.Adam(self.D.parameters(), lr = args.D_lr, betas=(args.b1, args.b2))\n",
    "        \n",
    "        if args.D_mode== 'Patch':\n",
    "            self.real_label = torch.ones(args.batch_size,1,4,4).to(device)\n",
    "            self.fake_label = torch.zeros(args.batch_size,1,4,4).to(device)\n",
    "        else:\n",
    "            self.real_label = torch.ones(args.batch_size,1,1,1).to(device)\n",
    "            self.fake_label = torch.zeros(args.batch_size,1,1,1).to(device)\n",
    "        \n",
    "        \n",
    "        self.apply(self.weight_init)\n",
    "        \n",
    "        self.progress_photo = []\n",
    "    \n",
    "    def forward(self, img, y):\n",
    "        \n",
    "        img = img.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        \n",
    "        one_hot_y = torch.zeros(args.batch_size,args.y_dim).to(device)\n",
    "        one_hot_y.scatter_(1,y.unsqueeze(1),1)\n",
    "        one_hot_y = one_hot_y.view(-1,args.y_dim,1,1)\n",
    "        \n",
    "        ############ Train D ############\n",
    "        self.D_optim.zero_grad()\n",
    "        self.G_img  = self.G(one_hot_y).detach()\n",
    "        D_fake_loss = self.Loss(self.D(self.G_img, one_hot_y),self.fake_label)\n",
    "        D_real_loss = self.Loss(self.D(img, one_hot_y),self.real_label)\n",
    "        self.D_loss = D_fake_loss + D_real_loss\n",
    "        self.D_loss_hist.append(self.D_loss.item())\n",
    "        self.D_loss.backward()\n",
    "        self.D_optim.step()\n",
    "        \n",
    "        ############ Train G ############\n",
    "        self.G_optim.zero_grad()\n",
    "        self.G_img = self.G(one_hot_y)\n",
    "        self.G_loss = self.Loss(self.D(self.G_img, one_hot_y),self.real_label)\n",
    "        self.G_loss_hist.append(self.G_loss.item())\n",
    "        self.G_loss.backward()\n",
    "        self.G_optim.step()\n",
    "        \n",
    "        self.progress_photo.append(self.G_img[0].detach())\n",
    "        self.progress_photo = self.progress_photo[-args.img_save_freq:]\n",
    "        \n",
    "    def image_save(self, step):\n",
    "        \n",
    "        img_save_path = args.img_path + \"cLSDCAN_Step_\"+str(step)+\".png\"\n",
    "        save_image( self.progress_photo[:args.img_save_freq], img_save_path , nrow=10, normalize=True, range=(-1,1))\n",
    "        print('Image saved')  \n",
    "        \n",
    "    def model_save(self,step):\n",
    "        path = args.model_path + 'cLSDCAN_Step_' + str(step) + '.pth'\n",
    "        torch.save({'cLSDCAN':self.state_dict()}, path)\n",
    "        print('Model saved')\n",
    "        \n",
    "    def load_step_dict(self, step):\n",
    "        \n",
    "        path = args.model_path + 'cLSDCAN_Step_' + str(step) + '.pth'\n",
    "        self.load_state_dict(torch.load(path, map_location=lambda storage, loc: storage)['cLSDCAN'])\n",
    " \n",
    "    def plot_all_loss(self,step):\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize= (20,8))\n",
    "        plt.plot(self.G_loss_hist,label='G_loss')\n",
    "        plt.plot(self.D_loss_hist,label='D_loss')\n",
    "        plt.ylabel('Loss',fontsize=15)\n",
    "        plt.xlabel('Number of Steps',fontsize=15)\n",
    "        plt.title('Loss',fontsize=30,fontweight =\"bold\")\n",
    "        plt.legend(loc = 'upper left')\n",
    "        fig.savefig(\"cLSDCAN_Loss_\"+str(step)+\".png\")\n",
    "        \n",
    "    def num_all_params(self,):\n",
    "        return sum([param.nelement() for param in self.parameters()])\n",
    "    \n",
    "    def weight_init(self,m):\n",
    "        if type(m) in [nn.Conv2d, nn.ConvTranspose2d]:\n",
    "            #nn.init.xavier_normal_(m.weight,nn.init.calculate_gain('leaky_relu',param=0.02))\n",
    "            nn.init.kaiming_normal_(m.weight,0.2,nonlinearity='leaky_relu')\n",
    "            \n",
    "        \n",
    "                \n",
    "dataset = CelebADataset(mode='train',args= args)\n",
    "training_loader = DataLoader(dataset,batch_size=args.batch_size,shuffle=True,drop_last=True,pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Choice of model:\n",
    "L_mode: LS, BCE\n",
    "G_mode: Upsample, Deconv\n",
    "D_mode: Normal, Patch (The Patch method need LS for L_mode)\n",
    "\n",
    "'''\n",
    "args.G_mode = 'Upsample'\n",
    "args.D_mode = 'Normal'\n",
    "args.L_mode = 'LS'\n",
    "gan = cLSDCGAN().to(device)\n",
    "epoch = 0\n",
    "all_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while epoch < args.n_epoch:\n",
    "    for i, (img, y) in enumerate(training_loader):    \n",
    "        \n",
    "        start_t = time.time()\n",
    "        gan(img, y)\n",
    "        end_t = time.time()\n",
    "        \n",
    "        print('| Epoch [%d] | Step [%d] | D Loss: [%.4f] | G Loss: [%.4f] | Time: %.1fs' %\\\n",
    "              (epoch, all_steps, gan.D_loss.item(), gan.G_loss.item(),\n",
    "               end_t - start_t))\n",
    "\n",
    "        if all_steps % args.show_freq == 0: #args.show_freq\n",
    "            fig=plt.figure(figsize=(8, 8))\n",
    "            fig.add_subplot(1,3,1)\n",
    "            plt.imshow(to_img(gan.G_img[0].cpu()*0.5+0.5))\n",
    "            plt.show()\n",
    "            if all_steps % args.img_save_freq ==0: # args.img_save_freq\n",
    "                gan.image_save(all_steps)\n",
    "                if all_steps % args.model_save_freq == 0: #args.model_save_freq\n",
    "                    gan.model_save(all_steps)\n",
    "        all_steps += 1\n",
    "    epoch +=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
